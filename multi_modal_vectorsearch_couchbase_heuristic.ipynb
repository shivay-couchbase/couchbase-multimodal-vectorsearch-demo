{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBPQ7UBgsrlS"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet datasets langchain-couchbase langchain-openai crewai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from math import ceil\n",
        "import os\n",
        "from pathlib import Path\n",
        "from random import choices\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer # The transformer used to execute the clip model.\n",
        "from tqdm.notebook import tqdm                        # Nice progress bars"
      ],
      "metadata": {
        "id": "1Adhs34jstAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.diagnostics import PingState, ServiceType\n",
        "from couchbase.exceptions import (InternalServerFailureException,\n",
        "                                  QueryIndexAlreadyExistsException,\n",
        "                                  ServiceUnavailableException)\n",
        "from couchbase.management.buckets import CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "crwSKFk1stCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "\n",
        "# Suppress httpx logging\n",
        "logging.getLogger('httpx').setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "T5gS_cbcstE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "CB_HOST = os.getenv('CB_HOST') or input(\"Enter Couchbase host (default: couchbase://localhost): \") or 'couchbase://localhost'\n",
        "CB_USERNAME = os.getenv('CB_USERNAME') or input(\"Enter Couchbase username (default: Administrator): \") or 'Administrator'\n",
        "CB_PASSWORD = os.getenv('CB_PASSWORD') or getpass.getpass(\"Enter Couchbase password (default: password): \") or 'password'\n",
        "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME') or input(\"Enter bucket name (default: vector-search-testing): \") or 'vector-search-testing'\n",
        "INDEX_NAME = os.getenv('INDEX_NAME') or input(\"Enter index name (default: vector_search_crew): \") or 'vector_search_crew'\n",
        "SCOPE_NAME = os.getenv('SCOPE_NAME') or input(\"Enter scope name (default: shared): \") or 'shared'\n",
        "COLLECTION_NAME = os.getenv('COLLECTION_NAME') or input(\"Enter collection name (default: crew): \") or 'crew'\n",
        "\n",
        "print(\"Configuration loaded successfully\")"
      ],
      "metadata": {
        "id": "eqO5p3Q4stHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Couchbase\n",
        "try:\n",
        "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
        "    options = ClusterOptions(auth)\n",
        "    cluster = Cluster(CB_HOST, options)\n",
        "    cluster.wait_until_ready(timedelta(seconds=5))\n",
        "    print(\"Successfully connected to Couchbase\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to connect to Couchbase: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "y9UwAD-0stJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load index definition\n",
        "try:\n",
        "    with open('crew_index.json', 'r') as file:\n",
        "        index_definition = json.load(file)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: crew_index.json file not found: {str(e)}\")\n",
        "    raise\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error: Invalid JSON in crew_index.json: {str(e)}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error loading index definition: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "jGIpelvKstMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
        "\n",
        "    # Check if index already exists\n",
        "    existing_indexes = scope_index_manager.get_all_indexes()\n",
        "    index_name = index_definition[\"name\"]\n",
        "\n",
        "    if index_name in [index.name for index in existing_indexes]:\n",
        "        logging.info(f\"Index '{index_name}' found\")\n",
        "    else:\n",
        "        logging.info(f\"Creating new index '{index_name}'...\")\n",
        "\n",
        "    # Create SearchIndex object from JSON definition\n",
        "    search_index = SearchIndex.from_json(index_definition)\n",
        "\n",
        "    # Upsert the index (create if not exists, update if exists)\n",
        "    scope_index_manager.upsert_index(search_index)\n",
        "    logging.info(f\"Index '{index_name}' successfully created/updated.\")\n",
        "\n",
        "except QueryIndexAlreadyExistsException:\n",
        "    logging.info(f\"Index '{index_name}' already exists. Skipping creation/update.\")\n",
        "except ServiceUnavailableException:\n",
        "    raise RuntimeError(\"Search service is not available. Please ensure the Search service is enabled in your Couchbase cluster.\")\n",
        "except InternalServerFailureException as e:\n",
        "    logging.error(f\"Internal server error: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "g0OqA1mWstO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CLIP model.\n",
        "# This may print out warnings, which can be ignored.\n",
        "model = SentenceTransformer(\"clip-ViT-L-14\")"
      ],
      "metadata": {
        "id": "o9HwVzBys8-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "# Load the JSON data\n",
        "with open('license_plates.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract all non-null image URLs\n",
        "image_urls = [\n",
        "    entry['p_license_plate_time_in_img_location']\n",
        "    for entry in data\n",
        "    if entry.get('p_license_plate_time_in_img_location')\n",
        "]\n",
        "\n",
        "print(f\"Found {len(image_urls)} images to download.\")\n",
        "\n",
        "for url in image_urls:\n",
        "    try:\n",
        "        # Get the filename from the URL\n",
        "        filename = os.path.basename(urlparse(url).path)\n",
        "        dest_path = os.path.join('images', filename)\n",
        "\n",
        "        # Download and save the image\n",
        "        resp = requests.get(url, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "        with open(dest_path, 'wb') as f:\n",
        "            f.write(resp.content)\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {url}: {e}\")\n"
      ],
      "metadata": {
        "id": "a-H_UsSrs9A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from random import choices\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.options import ClusterOptions\n",
        "from couchbase.exceptions import DocumentExistsException\n",
        "\n",
        "\n",
        "# Connect to Couchbase\n",
        "auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
        "cluster = Cluster(CB_HOST, ClusterOptions(auth))\n",
        "bucket = cluster.bucket(CB_BUCKET_NAME)\n",
        "cb_collection = bucket.scope(SCOPE_NAME).collection(COLLECTION_NAME)\n",
        "\n",
        "def load_images(image_count=1000):\n",
        "    \"\"\"\n",
        "    Load `image_count` images into Couchbase, creating an embedding for each.\n",
        "    \"\"\"\n",
        "    # Fix the file extension to .jpg instead of .JPEG\n",
        "    image_paths = glob(\"images/**/*.jpg\", recursive=True)\n",
        "\n",
        "    if not image_paths:\n",
        "        print(\"No images found. Please check that the images folder exists and contains .jpg files.\")\n",
        "        return\n",
        "\n",
        "    # Use min() to avoid requesting more images than available\n",
        "    selected_paths = choices(image_paths, k=min(len(image_paths), image_count))\n",
        "\n",
        "    for path in tqdm(selected_paths):\n",
        "        emb = model.encode(Image.open(path))\n",
        "        doc_id = re.sub(\"images/\", \"\", path)\n",
        "\n",
        "        try:\n",
        "            # Fixed: changed document parameter to value\n",
        "            cb_collection.insert(\n",
        "                key=doc_id,\n",
        "                value={\n",
        "                    \"embedding\": emb.tolist(),\n",
        "                    \"path\": path  # Optional: Store original path if needed\n",
        "                }\n",
        "            )\n",
        "        except DocumentExistsException:\n",
        "            pass\n",
        "\n",
        "# Now call the function with your desired number of images\n",
        "NUMBER_OF_IMAGES_TO_LOAD = 200  # Set this to your desired number\n",
        "load_images(NUMBER_OF_IMAGES_TO_LOAD)"
      ],
      "metadata": {
        "id": "Gu73_KKFs9DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "from couchbase.search import SearchRequest, MatchNoneQuery\n",
        "from couchbase.options import SearchOptions  # Updated import location\n",
        "from couchbase.vector_search import VectorSearch, VectorQuery\n",
        "\n",
        "def image_search(search_phrase, limit=9):\n",
        "    \"\"\"\n",
        "    Use Couchbase Vector Search to search for a matching image.\n",
        "\n",
        "    The `search_phrase` is first converted to a vector embedding using\n",
        "    the `model` loaded earlier in the notebook. The vector is then used\n",
        "    to search Couchbase for matching images.\n",
        "    \"\"\"\n",
        "    # Convert search phrase to embedding\n",
        "    emb = model.encode(search_phrase)\n",
        "\n",
        "    # Create search request with vector search\n",
        "    search_req = SearchRequest.create(MatchNoneQuery()).with_vector_search(\n",
        "        VectorSearch.from_vector_query(\n",
        "            VectorQuery(\"embedding\", emb.tolist(), num_candidates=100)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set search options\n",
        "    search_options = SearchOptions(timeout=timedelta(seconds=5.0), limit=limit)\n",
        "\n",
        "    # Execute search\n",
        "    result = bucket.scope(SCOPE_NAME).search(INDEX_NAME, search_req, search_options)\n",
        "\n",
        "    # Process results\n",
        "    results = []\n",
        "    for row in result.rows():\n",
        "        try:\n",
        "            doc_result = cb_collection.get(row.id, timeout=timedelta(seconds=2.0))\n",
        "            # Using value instead of content\n",
        "            doc_value = doc_result.value\n",
        "            results.append({\n",
        "                \"id\": row.id,\n",
        "                \"score\": row.score,\n",
        "                \"path\": doc_value.get(\"path\")\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching document {row.id}: {str(e)}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OQcyooMks9Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_search(\"white colored car\")"
      ],
      "metadata": {
        "id": "3Jg1MSKDs9Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nVUobY7s9J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heuristic search for both license plate and images of cars\n"
      ],
      "metadata": {
        "id": "OMofdNQGrHBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from couchbase.exceptions import DocumentExistsException\n",
        "from random import choices\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "from random import choices\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.options import ClusterOptions\n",
        "from couchbase.exceptions import DocumentExistsException\n",
        "\n",
        "\n",
        "# Connect to Couchbase\n",
        "auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
        "cluster = Cluster(CB_HOST, ClusterOptions(auth))\n",
        "bucket = cluster.bucket(CB_BUCKET_NAME)\n",
        "cb_collection = bucket.scope(SCOPE_NAME).collection(COLLECTION_NAME)\n",
        "\n",
        "def load_images(image_count=1000, json_file=\"test.json\"):\n",
        "    \"\"\"\n",
        "    Load `image_count` images into Couchbase, creating an embedding for each.\n",
        "    Also includes license plate information by matching image names with JSON data.\n",
        "    \"\"\"\n",
        "    # Fix the file extension to .jpg instead of .JPEG\n",
        "    image_paths = glob(\"images/**/*.jpg\", recursive=True)\n",
        "\n",
        "    if not image_paths:\n",
        "        print(\"No images found. Please check that the images folder exists and contains .jpg files.\")\n",
        "        return\n",
        "\n",
        "    # Load license plate data from JSON\n",
        "    try:\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            license_data = json.load(f)\n",
        "        print(f\"Loaded {len(license_data)} license plate records from {json_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON file: {e}\")\n",
        "        license_data = []\n",
        "\n",
        "    # Create a dictionary to easily look up license plates by image name\n",
        "    license_lookup = {}\n",
        "    for item in license_data:\n",
        "        # Handle entry images - check if URL exists and is not None\n",
        "        if \"p_license_plate_time_in_img_location\" in item and item[\"p_license_plate_time_in_img_location\"]:\n",
        "            try:\n",
        "                url = item[\"p_license_plate_time_in_img_location\"]\n",
        "                filename = url.split(\"/\")[-1]\n",
        "                license_lookup[filename] = item[\"p_license_plate\"]\n",
        "            except AttributeError:\n",
        "                # Skip if URL is not a string or is None\n",
        "                pass\n",
        "\n",
        "        # Handle exit images - check if URL exists and is not None\n",
        "        if \"p_license_plate_time_out_img_location\" in item and item[\"p_license_plate_time_out_img_location\"]:\n",
        "            try:\n",
        "                url = item[\"p_license_plate_time_out_img_location\"]\n",
        "                filename = url.split(\"/\")[-1]\n",
        "                license_lookup[filename] = item[\"p_license_plate\"]\n",
        "            except AttributeError:\n",
        "                # Skip if URL is not a string or is None\n",
        "                pass\n",
        "\n",
        "    print(f\"Created lookup table with {len(license_lookup)} entries\")\n",
        "\n",
        "    # Use min() to avoid requesting more images than available\n",
        "    selected_paths = choices(image_paths, k=min(len(image_paths), image_count))\n",
        "\n",
        "    for path in tqdm(selected_paths):\n",
        "        emb = model.encode(Image.open(path))\n",
        "        doc_id = re.sub(\"images/\", \"\", path)\n",
        "\n",
        "        # Extract just the filename from the path\n",
        "        filename = os.path.basename(path)\n",
        "\n",
        "        # Get license plate if available\n",
        "        license_plate = license_lookup.get(filename, \"\")\n",
        "\n",
        "        try:\n",
        "            cb_collection.insert(\n",
        "                key=doc_id,\n",
        "                value={\n",
        "                    \"embedding\": emb.tolist(),\n",
        "                    \"path\": path,\n",
        "                    \"license\": license_plate  # Add license plate info\n",
        "                }\n",
        "            )\n",
        "        except DocumentExistsException:\n",
        "            pass\n",
        "\n",
        "load_images(NUMBER_OF_IMAGES_TO_LOAD)"
      ],
      "metadata": {
        "id": "yTATK9r5rKhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "from couchbase.search import SearchRequest, MatchNoneQuery\n",
        "from couchbase.options import SearchOptions, QueryOptions\n",
        "from couchbase.vector_search import VectorSearch, VectorQuery\n",
        "import re\n",
        "\n",
        "def image_search(search_phrase, limit=9):\n",
        "    \"\"\"\n",
        "    Search for images in Couchbase using either vector search or license plate matching.\n",
        "\n",
        "    If the search phrase contains a license plate pattern, it extracts and uses that for a direct query.\n",
        "    Otherwise, it performs a vector search using the embedding.\n",
        "    \"\"\"\n",
        "    # First, try to extract license plate patterns from the search phrase\n",
        "    # Thai license plates typically have a format like: 1-4 digits + 1-2 Thai characters + 1-4 digits\n",
        "    license_pattern = re.search(r'(\\d{1,4}[ก-๙]{1,2}\\d{1,4})', search_phrase)\n",
        "\n",
        "    # If no exact pattern found, look for any sequence with Thai characters and numbers\n",
        "    if not license_pattern:\n",
        "        license_pattern = re.search(r'([0-9]+[ก-๙]+[0-9]+|[ก-๙]+[0-9]+[ก-๙]*|[0-9]+[ก-๙]*)', search_phrase)\n",
        "\n",
        "    results = []\n",
        "    extracted_plate = None\n",
        "\n",
        "    if license_pattern:\n",
        "        extracted_plate = license_pattern.group(1)\n",
        "        print(f\"Detected license plate pattern: {extracted_plate}\")\n",
        "\n",
        "        # Direct SQL++ query for license plate\n",
        "        query = f\"\"\"\n",
        "            SELECT META().id as id, 1.0 as score, `path`, license\n",
        "            FROM `{CB_BUCKET_NAME}`.`{SCOPE_NAME}`.`{COLLECTION_NAME}`\n",
        "            WHERE license LIKE $license\n",
        "            LIMIT {limit}\n",
        "        \"\"\"\n",
        "\n",
        "        # Use LIKE with wildcards for partial matching\n",
        "        params = {\"license\": f\"%{extracted_plate}%\"}\n",
        "\n",
        "        # Execute the query\n",
        "        try:\n",
        "            query_result = cluster.query(\n",
        "                query,\n",
        "                QueryOptions(named_parameters=params, timeout=timedelta(seconds=5.0))\n",
        "            )\n",
        "\n",
        "            # Process results\n",
        "            for row in query_result:\n",
        "                results.append({\n",
        "                    \"id\": row[\"id\"],\n",
        "                    \"score\": row[\"score\"],\n",
        "                    \"path\": row[\"path\"],\n",
        "                    \"license\": row[\"license\"],\n",
        "                    \"search_type\": \"license\",\n",
        "                    \"matched_pattern\": extracted_plate\n",
        "                })\n",
        "\n",
        "            if results:\n",
        "                return results  # Return early if we found matches\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"SQL++ query error: {str(e)}\")\n",
        "\n",
        "    # If no license plate pattern found or no results from license query, fall back to vector search\n",
        "    # Convert search phrase to embedding\n",
        "    emb = model.encode(search_phrase)\n",
        "\n",
        "    # Create search request with vector search\n",
        "    search_req = SearchRequest.create(MatchNoneQuery()).with_vector_search(\n",
        "        VectorSearch.from_vector_query(\n",
        "            VectorQuery(\"embedding\", emb.tolist(), num_candidates=100)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set search options\n",
        "    search_options = SearchOptions(timeout=timedelta(seconds=5.0), limit=limit)\n",
        "\n",
        "    # Execute search\n",
        "    result = bucket.scope(SCOPE_NAME).search(INDEX_NAME, search_req, search_options)\n",
        "\n",
        "    # Process results\n",
        "    for row in result.rows():\n",
        "        try:\n",
        "            doc_result = cb_collection.get(row.id, timeout=timedelta(seconds=2.0))\n",
        "            doc_value = doc_result.value\n",
        "            results.append({\n",
        "                \"id\": row.id,\n",
        "                \"score\": row.score,\n",
        "                \"path\": doc_value.get(\"path\"),\n",
        "                \"license\": doc_value.get(\"license\", \"\"),\n",
        "                \"search_type\": \"vector\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching document {row.id}: {str(e)}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "Din0kKhmrLPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_search(\"nissan car\")"
      ],
      "metadata": {
        "id": "pHreim1lrWDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_search(\"find the license number which is 4กฆ1289\")\n"
      ],
      "metadata": {
        "id": "E4HHybLgrWOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}